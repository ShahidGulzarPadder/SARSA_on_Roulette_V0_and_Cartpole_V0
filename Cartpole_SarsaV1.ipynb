{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cartpole-v0 \n",
    "# Shahid Gulzar Padder\n",
    "# XPXSKK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0.1 )the system  has converged  after  683  episodes.\n",
      "0.2 )the system  has converged  after  613  episodes.\n",
      "0.3 )the system  has converged  after  121  episodes.\n",
      "0.5 )the system  has converged  after  692  episodes.\n",
      "0.7 )the system  has converged  after  344  episodes.\n",
      "1\n",
      "0.1 )the system  has converged  after  587  episodes.\n",
      "0.2 )the system  has converged  after  317  episodes.\n",
      "0.3 )the system  has converged  after  389  episodes.\n",
      "0.5 )the system  has converged  after  693  episodes.\n",
      "0.7 )the system  has converged  after  296  episodes.\n",
      "2\n",
      "0.1 )the system  has converged  after  689  episodes.\n",
      "0.2 )the system  has converged  after  855  episodes.\n",
      "0.3 )the system  has converged  after  407  episodes.\n",
      "0.5 )the system  has converged  after  270  episodes.\n",
      "0.7 )the system  has converged  after  403  episodes.\n",
      "3\n",
      "0.1 )the system  has converged  after  674  episodes.\n",
      "0.2 )the system  has converged  after  365  episodes.\n",
      "0.3 )the system  has converged  after  1593  episodes.\n",
      "0.5 )the system  has converged  after  331  episodes.\n",
      "0.7 )the system  has converged  after  287  episodes.\n",
      "4\n",
      "0.1 )the system  has converged  after  1269  episodes.\n",
      "0.2 )the system  has converged  after  568  episodes.\n",
      "0.3 )the system  has converged  after  678  episodes.\n",
      "0.5 )the system  has converged  after  1054  episodes.\n",
      "0.7 )the system  has converged  after  584  episodes.\n",
      "5\n",
      "0.1 )the system  has converged  after  272  episodes.\n",
      "0.2 )the system  has converged  after  490  episodes.\n",
      "0.3 )the system  has converged  after  633  episodes.\n",
      "0.5 )the system  has converged  after  406  episodes.\n",
      "0.7 )the system  has converged  after  411  episodes.\n",
      "6\n",
      "0.1 )the system  has converged  after  173  episodes.\n",
      "0.2 )the system  has converged  after  752  episodes.\n",
      "0.3 )the system  has converged  after  754  episodes.\n",
      "0.5 )the system  has converged  after  275  episodes.\n",
      "0.7 )the system  has converged  after  594  episodes.\n",
      "7\n",
      "0.1 )the system  has converged  after  1019  episodes.\n",
      "0.2 )the system  has converged  after  623  episodes.\n",
      "0.3 )the system  has converged  after  695  episodes.\n",
      "0.5 )the system  has converged  after  621  episodes.\n",
      "0.7 )the system  has converged  after  376  episodes.\n",
      "8\n",
      "0.1 )the system  has converged  after  160  episodes.\n",
      "0.2 )the system  has converged  after  461  episodes.\n",
      "0.3 )the system  has converged  after  429  episodes.\n",
      "0.5 )the system  has converged  after  476  episodes.\n",
      "0.7 )the system  has converged  after  399  episodes.\n",
      "9\n",
      "0.1 )the system  has converged  after  475  episodes.\n",
      "0.2 )the system  has converged  after  917  episodes.\n",
      "0.3 )the system  has converged  after  266  episodes.\n",
      "0.5 )the system  has converged  after  284  episodes.\n",
      "0.7 )the system  has converged  after  1104  episodes.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas\n",
    "import numpy as np\n",
    "import numpy.random as rnd\n",
    "import gym\n",
    "import itertools\n",
    "from collections import defaultdict\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def make_eps_greedy_policy(Q, eps, n):\n",
    "    \"\"\"Define a policy.\n",
    "    Parameters\n",
    "    ----------\n",
    "    Q : array_like (n_states x n_actions)\n",
    "        Action-values.\n",
    "    eps : float\n",
    "        Eps-greedy factor.\n",
    "    n : integer\n",
    "        Number of actions.\n",
    "    Returns\n",
    "    -------\n",
    "    policy : function\n",
    "        Function that returns actions given an input state (the present state).\n",
    "    \"\"\"\n",
    "    def policy(state):\n",
    "        \"\"\"Define a set of actions.\n",
    "        Parameters\n",
    "        ----------\n",
    "        state : tuple\n",
    "            Present state on which depends our next action.\n",
    "        Retuns\n",
    "        ------\n",
    "        A : array\n",
    "            Probabilities for actions in the set of possible actions to be taken.\n",
    "        \"\"\"\n",
    "        A = np.ones(n, dtype=float) * eps/n\n",
    "        best = np.argmax(Q[state])\n",
    "        A[best] += 1 - eps\n",
    "        return A\n",
    "    return policy\n",
    "\n",
    "def sarsa_control(env, max_num_episodes, discount=1.0, eps=0.99, alpha=0.05):\n",
    "    \"\"\"Sarsa control.\n",
    "    Parameters\n",
    "    ----------\n",
    "    env : OpenAI gym environment\n",
    "        Environment which will be used in the simulation (CartPole-v0).\n",
    "    max_num_episodes : int\n",
    "        Max number of episodes to converge.\n",
    "    discount : float\n",
    "        Discount factor.\n",
    "    eps : float\n",
    "        Exploration rate (since we are using an epsilon-greedy policy).\n",
    "    eps_decay : float\n",
    "        Exploration rate decay over episodes.\n",
    "    eps_min : float\n",
    "        Min exploration rate reachable.\n",
    "    Returns\n",
    "    -------\n",
    "    converged : bool\n",
    "        True if the algorithm converged, False otherwise.\n",
    "    num_episodes : int\n",
    "        Number of episodes to converge.\n",
    "    \"\"\"\n",
    "    Q = defaultdict(lambda: np.zeros(env.action_space.n))\n",
    "    possible_actions = np.arange(env.action_space.n)\n",
    "    converged = False\n",
    "    returns = []\n",
    "\n",
    "    for num_episodes in range(max_num_episodes):\n",
    "        totalreward = 0     # total reward in this episodes (+1 each step)\n",
    "        state = build_state(env.reset())\n",
    "        policy = make_eps_greedy_policy(Q, eps, env.action_space.n)\n",
    "        probs = policy(state)\n",
    "        action = rnd.choice(possible_actions, p=probs)\n",
    "\n",
    "        for t in itertools.count():\n",
    "            # take the current action and observe the reward\n",
    "            next_state, reward, done, _ = env.step(action)\n",
    "            next_state = build_state(next_state)\n",
    "\n",
    "            # predict next action\n",
    "            probs = policy(next_state)\n",
    "            next_action = rnd.choice(possible_actions, p=probs)\n",
    "\n",
    "            # if the cartpole system fell down during this episode\n",
    "            if (done):\n",
    "                # high penalization helps the convergence\n",
    "                Q[state][action] += -200\n",
    "                totalreward += reward\n",
    "                returns.append(totalreward)\n",
    "                break\n",
    "\n",
    "            # update Q-values using Sarsa update rule\n",
    "            Q[state][action] = Q[state][action] + alpha*(reward + discount*Q[next_state][next_action] - Q[state][action])\n",
    "\n",
    "            # append this step's reward\n",
    "            totalreward += reward\n",
    "\n",
    "            state, action = next_state, next_action\n",
    "\n",
    "        # we are not decaying in the sensibility analysis\n",
    "        #if i%100 == 0:\n",
    "        #    eps *= eps_decay\n",
    "        #    if (eps < eps_min):\n",
    "        #        eps = eps_min\n",
    "\n",
    "        # winning condition: last 100 episodes have a mean of WINNING_MEAN total reward\n",
    "        mean = np.mean(returns[-100:])\n",
    "        if mean >= WINNING_MEAN:\n",
    "            converged = True\n",
    "            break\n",
    "\n",
    "    return converged, num_episodes\n",
    "\n",
    "def build_state(state):\n",
    "    \"\"\"Discretize the state returned by the environment.\n",
    "    Parameters\n",
    "    ----------\n",
    "    state : tuple\n",
    "        State returned by OpenAI gym environment.\n",
    "    Returns\n",
    "    -------\n",
    "    _ : tuple\n",
    "        The correspondent discrete state.\n",
    "    \"\"\"\n",
    "    return (np.digitize([state[0]], cart_position_bins)[0],\n",
    "            np.digitize([state[1]], cart_velocity_bins)[0],\n",
    "            np.digitize([state[2]], pole_angle_bins)[0],\n",
    "            np.digitize([state[3]], angle_rate_bins)[0])\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    env = gym.make('CartPole-v0')\n",
    "    max_num_episodes = 6000\n",
    "    discount = 0.999\n",
    "    eps = 0.001\n",
    "    #eps_decay = 0.0\n",
    "    #eps_min = 0.01\n",
    "    alpha = 0.2\n",
    "\n",
    "    NUM_ITERATIONS = 10\n",
    "    WINNING_MEAN = 170\n",
    "    EPS_ANALYSIS = 0\n",
    "    ALPHA_ANALYSIS = 1\n",
    "    DISCOUNT_ANALYSIS = 2\n",
    "    mode = ALPHA_ANALYSIS\n",
    "\n",
    "    # number of discrete states\n",
    "    n_bins = 8\n",
    "    n_bins_angle = 10\n",
    "\n",
    "    # discrete states for each variable\n",
    "    cart_position_bins = pandas.cut([-2.4, 2.4], bins=n_bins, retbins=True)[1][1:-1]\n",
    "    cart_velocity_bins = pandas.cut([-1, 1], bins=n_bins, retbins=True)[1][1:-1]\n",
    "    pole_angle_bins = pandas.cut([-2, 2], bins=n_bins_angle, retbins=True)[1][1:-1]\n",
    "    angle_rate_bins = pandas.cut([-3.5, 3.5], bins=n_bins_angle, retbins=True)[1][1:-1]\n",
    "\n",
    "    array_eps_to_conv = []\n",
    "    if (mode == EPS_ANALYSIS):\n",
    "        eval_array = [0.001,0.003,0.006,0.01,0.013]\n",
    "    elif (mode == ALPHA_ANALYSIS):\n",
    "        eval_array = [0.1,0.2,0.3,0.5,0.7]\n",
    "    else:\n",
    "        eval_array = [0.999,0.8,0.7,0.6,0.5]\n",
    "\n",
    "    for t in range(NUM_ITERATIONS):\n",
    "        array_temp = []\n",
    "        print(t)\n",
    "\n",
    "        for hyperparameter in eval_array:\n",
    "            if (mode == EPS_ANALYSIS):\n",
    "                has_converged, episodes_to_converge = sarsa_control(env, max_num_episodes, discount, hyperparameter, alpha)\n",
    "            elif (mode == ALPHA_ANALYSIS):\n",
    "                has_converged, episodes_to_converge = sarsa_control(env, max_num_episodes, discount, eps, hyperparameter)\n",
    "            else:\n",
    "                has_converged, episodes_to_converge = sarsa_control(env, max_num_episodes, hyperparameter, eps, alpha)\n",
    "\n",
    "            array_temp.append(episodes_to_converge)\n",
    "            print(hyperparameter, \")the system \", \"has converged\" if (has_converged) else \"hasn't converged\", \" after \", episodes_to_converge, \" episodes.\")\n",
    "\n",
    "        array_eps_to_conv.append(array_temp)\n",
    "\n",
    "    array_eps_to_conv = np.array(array_eps_to_conv)\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111)\n",
    "\n",
    "    if (mode == EPS_ANALYSIS):\n",
    "        title = r'$\\gamma = {:.3f}; \\alpha = {:.3f}$'.format(discount, alpha)\n",
    "        label = r'$\\epsilon$'\n",
    "        name = 'eps_sensibility1.png'\n",
    "        ax.set_ylim((0,2000))\n",
    "    elif (mode == ALPHA_ANALYSIS):\n",
    "        title = r'$\\gamma = {:.3f}; \\epsilon = {:.3f}$'.format(discount, eps)\n",
    "        label = r'$\\alpha$'\n",
    "        name = 'lr_sensibility1.png'\n",
    "        ax.set_ylim((0,1000))\n",
    "    else:\n",
    "        title = r'$\\alpha = {:.3f}; \\epsilon = {:.3f}$'.format(alpha, eps)\n",
    "        label = r'$1-\\gamma$'\n",
    "        eval_array = [np.around(1-disc, decimals=4) for disc in eval_array]\n",
    "        name = 'discount_sensibility1.png'\n",
    "        ax.set_ylim((0,1500))\n",
    "\n",
    "    ax.set_title(title)\n",
    "    ax.set_ylabel('episodes to converge')\n",
    "    ax.set_xlabel(label)\n",
    "    ax.boxplot(array_eps_to_conv, labels=eval_array)\n",
    "    plt.savefig(name)\n",
    "    #plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0.001 )the system  has converged  after  388  episodes.\n",
      "0.003 )the system  has converged  after  970  episodes.\n",
      "0.006 )the system  has converged  after  734  episodes.\n",
      "0.01 )the system  has converged  after  1233  episodes.\n",
      "0.013 )the system  has converged  after  705  episodes.\n",
      "1\n",
      "0.001 )the system  has converged  after  451  episodes.\n",
      "0.003 )the system  has converged  after  393  episodes.\n",
      "0.006 )the system  has converged  after  1212  episodes.\n",
      "0.01 )the system  has converged  after  964  episodes.\n",
      "0.013 )the system  has converged  after  713  episodes.\n",
      "2\n",
      "0.001 )the system  has converged  after  671  episodes.\n",
      "0.003 )the system  has converged  after  618  episodes.\n",
      "0.006 )the system  has converged  after  2165  episodes.\n",
      "0.01 )the system  has converged  after  1254  episodes.\n",
      "0.013 )the system  has converged  after  1143  episodes.\n",
      "3\n",
      "0.001 )the system  has converged  after  635  episodes.\n",
      "0.003 )the system  has converged  after  641  episodes.\n",
      "0.006 )the system  has converged  after  635  episodes.\n",
      "0.01 )the system  has converged  after  884  episodes.\n",
      "0.013 )the system  has converged  after  1320  episodes.\n",
      "4\n",
      "0.001 )the system  has converged  after  1049  episodes.\n",
      "0.003 )the system  has converged  after  429  episodes.\n",
      "0.006 )the system  has converged  after  887  episodes.\n",
      "0.01 )the system  has converged  after  1270  episodes.\n",
      "0.013 )the system  has converged  after  2089  episodes.\n",
      "5\n",
      "0.001 )the system  has converged  after  286  episodes.\n",
      "0.003 )the system  has converged  after  444  episodes.\n",
      "0.006 )the system  has converged  after  1191  episodes.\n",
      "0.01 )the system  has converged  after  710  episodes.\n",
      "0.013 )the system  has converged  after  1218  episodes.\n",
      "6\n",
      "0.001 )the system  has converged  after  133  episodes.\n",
      "0.003 )the system  has converged  after  954  episodes.\n",
      "0.006 )the system  has converged  after  774  episodes.\n",
      "0.01 )the system  has converged  after  1032  episodes.\n",
      "0.013 )the system  has converged  after  625  episodes.\n",
      "7\n",
      "0.001 )the system  has converged  after  761  episodes.\n",
      "0.003 )the system  has converged  after  150  episodes.\n",
      "0.006 )the system  has converged  after  402  episodes.\n",
      "0.01 )the system  has converged  after  717  episodes.\n",
      "0.013 )the system  has converged  after  640  episodes.\n",
      "8\n",
      "0.001 )the system  has converged  after  798  episodes.\n",
      "0.003 )the system  has converged  after  1571  episodes.\n",
      "0.006 )the system  has converged  after  280  episodes.\n",
      "0.01 )the system  has converged  after  1064  episodes.\n",
      "0.013 )the system  has converged  after  555  episodes.\n",
      "9\n",
      "0.001 )the system  has converged  after  426  episodes.\n",
      "0.003 )the system  has converged  after  385  episodes.\n",
      "0.006 )the system  has converged  after  679  episodes.\n",
      "0.01 )the system  has converged  after  357  episodes.\n",
      "0.013 )the system  has converged  after  1765  episodes.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas\n",
    "import numpy as np\n",
    "import numpy.random as rnd\n",
    "import gym\n",
    "import itertools\n",
    "from collections import defaultdict\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def make_eps_greedy_policy(Q, eps, n):\n",
    "    \"\"\"Define a policy.\n",
    "    Parameters\n",
    "    ----------\n",
    "    Q : array_like (n_states x n_actions)\n",
    "        Action-values.\n",
    "    eps : float\n",
    "        Eps-greedy factor.\n",
    "    n : integer\n",
    "        Number of actions.\n",
    "    Returns\n",
    "    -------\n",
    "    policy : function\n",
    "        Function that returns actions given an input state (the present state).\n",
    "    \"\"\"\n",
    "    def policy(state):\n",
    "        \"\"\"Define a set of actions.\n",
    "        Parameters\n",
    "        ----------\n",
    "        state : tuple\n",
    "            Present state on which depends our next action.\n",
    "        Retuns\n",
    "        ------\n",
    "        A : array\n",
    "            Probabilities for actions in the set of possible actions to be taken.\n",
    "        \"\"\"\n",
    "        A = np.ones(n, dtype=float) * eps/n\n",
    "        best = np.argmax(Q[state])\n",
    "        A[best] += 1 - eps\n",
    "        return A\n",
    "    return policy\n",
    "\n",
    "def sarsa_control(env, max_num_episodes, discount=1.0, eps=0.99, alpha=0.05):\n",
    "    \"\"\"Sarsa control.\n",
    "    Parameters\n",
    "    ----------\n",
    "    env : OpenAI gym environment\n",
    "        Environment which will be used in the simulation (CartPole-v0).\n",
    "    max_num_episodes : int\n",
    "        Max number of episodes to converge.\n",
    "    discount : float\n",
    "        Discount factor.\n",
    "    eps : float\n",
    "        Exploration rate (since we are using an epsilon-greedy policy).\n",
    "    eps_decay : float\n",
    "        Exploration rate decay over episodes.\n",
    "    eps_min : float\n",
    "        Min exploration rate reachable.\n",
    "    Returns\n",
    "    -------\n",
    "    converged : bool\n",
    "        True if the algorithm converged, False otherwise.\n",
    "    num_episodes : int\n",
    "        Number of episodes to converge.\n",
    "    \"\"\"\n",
    "    Q = defaultdict(lambda: np.zeros(env.action_space.n))\n",
    "    possible_actions = np.arange(env.action_space.n)\n",
    "    converged = False\n",
    "    returns = []\n",
    "\n",
    "    for num_episodes in range(max_num_episodes):\n",
    "        totalreward = 0     # total reward in this episodes (+1 each step)\n",
    "        state = build_state(env.reset())\n",
    "        policy = make_eps_greedy_policy(Q, eps, env.action_space.n)\n",
    "        probs = policy(state)\n",
    "        action = rnd.choice(possible_actions, p=probs)\n",
    "\n",
    "        for t in itertools.count():\n",
    "            # take the current action and observe the reward\n",
    "            next_state, reward, done, _ = env.step(action)\n",
    "            next_state = build_state(next_state)\n",
    "\n",
    "            # predict next action\n",
    "            probs = policy(next_state)\n",
    "            next_action = rnd.choice(possible_actions, p=probs)\n",
    "\n",
    "            # if the cartpole system fell down during this episode\n",
    "            if (done):\n",
    "                # high penalization helps the convergence\n",
    "                Q[state][action] += -200\n",
    "                totalreward += reward\n",
    "                returns.append(totalreward)\n",
    "                break\n",
    "\n",
    "            # update Q-values using Sarsa update rule\n",
    "            Q[state][action] = Q[state][action] + alpha*(reward + discount*Q[next_state][next_action] - Q[state][action])\n",
    "\n",
    "            # append this step's reward\n",
    "            totalreward += reward\n",
    "\n",
    "            state, action = next_state, next_action\n",
    "\n",
    "        # we are not decaying in the sensibility analysis\n",
    "        #if i%100 == 0:\n",
    "        #    eps *= eps_decay\n",
    "        #    if (eps < eps_min):\n",
    "        #        eps = eps_min\n",
    "\n",
    "        # winning condition: last 100 episodes have a mean of WINNING_MEAN total reward\n",
    "        mean = np.mean(returns[-100:])\n",
    "        if mean >= WINNING_MEAN:\n",
    "            converged = True\n",
    "            break\n",
    "\n",
    "    return converged, num_episodes\n",
    "\n",
    "def build_state(state):\n",
    "    \"\"\"Discretize the state returned by the environment.\n",
    "    Parameters\n",
    "    ----------\n",
    "    state : tuple\n",
    "        State returned by OpenAI gym environment.\n",
    "    Returns\n",
    "    -------\n",
    "    _ : tuple\n",
    "        The correspondent discrete state.\n",
    "    \"\"\"\n",
    "    return (np.digitize([state[0]], cart_position_bins)[0],\n",
    "            np.digitize([state[1]], cart_velocity_bins)[0],\n",
    "            np.digitize([state[2]], pole_angle_bins)[0],\n",
    "            np.digitize([state[3]], angle_rate_bins)[0])\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    env = gym.make('CartPole-v0')\n",
    "    max_num_episodes = 6000\n",
    "    discount = 0.999\n",
    "    eps = 0.001\n",
    "    #eps_decay = 0.0\n",
    "    #eps_min = 0.01\n",
    "    alpha = 0.2\n",
    "\n",
    "    NUM_ITERATIONS = 10\n",
    "    WINNING_MEAN = 170\n",
    "    EPS_ANALYSIS = 0\n",
    "    ALPHA_ANALYSIS = 1\n",
    "    DISCOUNT_ANALYSIS = 2\n",
    "    mode = EPS_ANALYSIS\n",
    "\n",
    "    # number of discrete states\n",
    "    n_bins = 8\n",
    "    n_bins_angle = 10\n",
    "\n",
    "    # discrete states for each variable\n",
    "    cart_position_bins = pandas.cut([-2.4, 2.4], bins=n_bins, retbins=True)[1][1:-1]\n",
    "    cart_velocity_bins = pandas.cut([-1, 1], bins=n_bins, retbins=True)[1][1:-1]\n",
    "    pole_angle_bins = pandas.cut([-2, 2], bins=n_bins_angle, retbins=True)[1][1:-1]\n",
    "    angle_rate_bins = pandas.cut([-3.5, 3.5], bins=n_bins_angle, retbins=True)[1][1:-1]\n",
    "\n",
    "    array_eps_to_conv = []\n",
    "    if (mode == EPS_ANALYSIS):\n",
    "        eval_array = [0.001,0.003,0.006,0.01,0.013]\n",
    "    elif (mode == ALPHA_ANALYSIS):\n",
    "        eval_array = [0.1,0.2,0.3,0.5,0.7]\n",
    "    else:\n",
    "        eval_array = [0.999,0.8,0.7,0.6,0.5]\n",
    "\n",
    "    for t in range(NUM_ITERATIONS):\n",
    "        array_temp = []\n",
    "        print(t)\n",
    "\n",
    "        for hyperparameter in eval_array:\n",
    "            if (mode == EPS_ANALYSIS):\n",
    "                has_converged, episodes_to_converge = sarsa_control(env, max_num_episodes, discount, hyperparameter, alpha)\n",
    "            elif (mode == ALPHA_ANALYSIS):\n",
    "                has_converged, episodes_to_converge = sarsa_control(env, max_num_episodes, discount, eps, hyperparameter)\n",
    "            else:\n",
    "                has_converged, episodes_to_converge = sarsa_control(env, max_num_episodes, hyperparameter, eps, alpha)\n",
    "\n",
    "            array_temp.append(episodes_to_converge)\n",
    "            print(hyperparameter, \")the system \", \"has converged\" if (has_converged) else \"hasn't converged\", \" after \", episodes_to_converge, \" episodes.\")\n",
    "\n",
    "        array_eps_to_conv.append(array_temp)\n",
    "\n",
    "    array_eps_to_conv = np.array(array_eps_to_conv)\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111)\n",
    "\n",
    "    if (mode == EPS_ANALYSIS):\n",
    "        title = r'$\\gamma = {:.3f}; \\alpha = {:.3f}$'.format(discount, alpha)\n",
    "        label = r'$\\epsilon$'\n",
    "        name = 'eps_sensibility1.png'\n",
    "        ax.set_ylim((0,2000))\n",
    "    elif (mode == ALPHA_ANALYSIS):\n",
    "        title = r'$\\gamma = {:.3f}; \\epsilon = {:.3f}$'.format(discount, eps)\n",
    "        label = r'$\\alpha$'\n",
    "        name = 'lr_sensibility1.png'\n",
    "        ax.set_ylim((0,1000))\n",
    "    else:\n",
    "        title = r'$\\alpha = {:.3f}; \\epsilon = {:.3f}$'.format(alpha, eps)\n",
    "        label = r'$1-\\gamma$'\n",
    "        eval_array = [np.around(1-disc, decimals=4) for disc in eval_array]\n",
    "        name = 'discount_sensibility1.png'\n",
    "        ax.set_ylim((0,1500))\n",
    "\n",
    "    ax.set_title(title)\n",
    "    ax.set_ylabel('episodes to converge')\n",
    "    ax.set_xlabel(label)\n",
    "    ax.boxplot(array_eps_to_conv, labels=eval_array)\n",
    "    plt.savefig(name)\n",
    "    #plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0.999 )the system  has converged  after  585  episodes.\n",
      "0.8 )the system  has converged  after  516  episodes.\n",
      "0.7 )the system  has converged  after  1720  episodes.\n",
      "0.6 )the system  has converged  after  4259  episodes.\n",
      "0.5 )the system  hasn't converged  after  5999  episodes.\n",
      "1\n",
      "0.999 )the system  has converged  after  328  episodes.\n",
      "0.8 )the system  has converged  after  708  episodes.\n",
      "0.7 )the system  has converged  after  787  episodes.\n",
      "0.6 )the system  has converged  after  1298  episodes.\n",
      "0.5 )the system  has converged  after  1422  episodes.\n",
      "2\n",
      "0.999 )the system  has converged  after  274  episodes.\n",
      "0.8 )the system  has converged  after  410  episodes.\n",
      "0.7 )the system  has converged  after  1780  episodes.\n",
      "0.6 )the system  has converged  after  1990  episodes.\n",
      "0.5 )the system  has converged  after  984  episodes.\n",
      "3\n",
      "0.999 )the system  has converged  after  1766  episodes.\n",
      "0.8 )the system  has converged  after  366  episodes.\n",
      "0.7 )the system  has converged  after  488  episodes.\n",
      "0.6 )the system  has converged  after  1143  episodes.\n",
      "0.5 )the system  has converged  after  1765  episodes.\n",
      "4\n",
      "0.999 )the system  has converged  after  808  episodes.\n",
      "0.8 )the system  has converged  after  421  episodes.\n",
      "0.7 )the system  has converged  after  1383  episodes.\n",
      "0.6 )the system  has converged  after  2328  episodes.\n",
      "0.5 )the system  has converged  after  457  episodes.\n",
      "5\n",
      "0.999 )the system  has converged  after  374  episodes.\n",
      "0.8 )the system  has converged  after  330  episodes.\n",
      "0.7 )the system  has converged  after  1225  episodes.\n",
      "0.6 )the system  has converged  after  387  episodes.\n",
      "0.5 )the system  has converged  after  1555  episodes.\n",
      "6\n",
      "0.999 )the system  has converged  after  548  episodes.\n",
      "0.8 )the system  has converged  after  684  episodes.\n",
      "0.7 )the system  has converged  after  1087  episodes.\n",
      "0.6 )the system  has converged  after  794  episodes.\n",
      "0.5 )the system  has converged  after  1541  episodes.\n",
      "7\n",
      "0.999 )the system  has converged  after  312  episodes.\n",
      "0.8 )the system  has converged  after  206  episodes.\n",
      "0.7 )the system  has converged  after  1173  episodes.\n",
      "0.6 )the system  has converged  after  1437  episodes.\n",
      "0.5 )the system  has converged  after  579  episodes.\n",
      "8\n",
      "0.999 )the system  has converged  after  1230  episodes.\n",
      "0.8 )the system  has converged  after  239  episodes.\n",
      "0.7 )the system  has converged  after  697  episodes.\n",
      "0.6 )the system  has converged  after  419  episodes.\n",
      "0.5 )the system  has converged  after  1228  episodes.\n",
      "9\n",
      "0.999 )the system  has converged  after  625  episodes.\n",
      "0.8 )the system  has converged  after  410  episodes.\n",
      "0.7 )the system  has converged  after  2244  episodes.\n",
      "0.6 )the system  has converged  after  469  episodes.\n",
      "0.5 )the system  has converged  after  1956  episodes.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas\n",
    "import numpy as np\n",
    "import numpy.random as rnd\n",
    "import gym\n",
    "import itertools\n",
    "from collections import defaultdict\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def make_eps_greedy_policy(Q, eps, n):\n",
    "    \"\"\"Define a policy.\n",
    "    Parameters\n",
    "    ----------\n",
    "    Q : array_like (n_states x n_actions)\n",
    "        Action-values.\n",
    "    eps : float\n",
    "        Eps-greedy factor.\n",
    "    n : integer\n",
    "        Number of actions.\n",
    "    Returns\n",
    "    -------\n",
    "    policy : function\n",
    "        Function that returns actions given an input state (the present state).\n",
    "    \"\"\"\n",
    "    def policy(state):\n",
    "        \"\"\"Define a set of actions.\n",
    "        Parameters\n",
    "        ----------\n",
    "        state : tuple\n",
    "            Present state on which depends our next action.\n",
    "        Retuns\n",
    "        ------\n",
    "        A : array\n",
    "            Probabilities for actions in the set of possible actions to be taken.\n",
    "        \"\"\"\n",
    "        A = np.ones(n, dtype=float) * eps/n\n",
    "        best = np.argmax(Q[state])\n",
    "        A[best] += 1 - eps\n",
    "        return A\n",
    "    return policy\n",
    "\n",
    "def sarsa_control(env, max_num_episodes, discount=1.0, eps=0.99, alpha=0.05):\n",
    "    \"\"\"Sarsa control.\n",
    "    Parameters\n",
    "    ----------\n",
    "    env : OpenAI gym environment\n",
    "        Environment which will be used in the simulation (CartPole-v0).\n",
    "    max_num_episodes : int\n",
    "        Max number of episodes to converge.\n",
    "    discount : float\n",
    "        Discount factor.\n",
    "    eps : float\n",
    "        Exploration rate (since we are using an epsilon-greedy policy).\n",
    "    eps_decay : float\n",
    "        Exploration rate decay over episodes.\n",
    "    eps_min : float\n",
    "        Min exploration rate reachable.\n",
    "    Returns\n",
    "    -------\n",
    "    converged : bool\n",
    "        True if the algorithm converged, False otherwise.\n",
    "    num_episodes : int\n",
    "        Number of episodes to converge.\n",
    "    \"\"\"\n",
    "    Q = defaultdict(lambda: np.zeros(env.action_space.n))\n",
    "    possible_actions = np.arange(env.action_space.n)\n",
    "    converged = False\n",
    "    returns = []\n",
    "\n",
    "    for num_episodes in range(max_num_episodes):\n",
    "        totalreward = 0     # total reward in this episodes (+1 each step)\n",
    "        state = build_state(env.reset())\n",
    "        policy = make_eps_greedy_policy(Q, eps, env.action_space.n)\n",
    "        probs = policy(state)\n",
    "        action = rnd.choice(possible_actions, p=probs)\n",
    "\n",
    "        for t in itertools.count():\n",
    "            # take the current action and observe the reward\n",
    "            next_state, reward, done, _ = env.step(action)\n",
    "            next_state = build_state(next_state)\n",
    "\n",
    "            # predict next action\n",
    "            probs = policy(next_state)\n",
    "            next_action = rnd.choice(possible_actions, p=probs)\n",
    "\n",
    "            # if the cartpole system fell down during this episode\n",
    "            if (done):\n",
    "                # high penalization helps the convergence\n",
    "                Q[state][action] += -200\n",
    "                totalreward += reward\n",
    "                returns.append(totalreward)\n",
    "                break\n",
    "\n",
    "            # update Q-values using Sarsa update rule\n",
    "            Q[state][action] = Q[state][action] + alpha*(reward + discount*Q[next_state][next_action] - Q[state][action])\n",
    "\n",
    "            # append this step's reward\n",
    "            totalreward += reward\n",
    "\n",
    "            state, action = next_state, next_action\n",
    "\n",
    "        # we are not decaying in the sensibility analysis\n",
    "        #if i%100 == 0:\n",
    "        #    eps *= eps_decay\n",
    "        #    if (eps < eps_min):\n",
    "        #        eps = eps_min\n",
    "\n",
    "        # winning condition: last 100 episodes have a mean of WINNING_MEAN total reward\n",
    "        mean = np.mean(returns[-100:])\n",
    "        if mean >= WINNING_MEAN:\n",
    "            converged = True\n",
    "            break\n",
    "\n",
    "    return converged, num_episodes\n",
    "\n",
    "def build_state(state):\n",
    "    \"\"\"Discretize the state returned by the environment.\n",
    "    Parameters\n",
    "    ----------\n",
    "    state : tuple\n",
    "        State returned by OpenAI gym environment.\n",
    "    Returns\n",
    "    -------\n",
    "    _ : tuple\n",
    "        The correspondent discrete state.\n",
    "    \"\"\"\n",
    "    return (np.digitize([state[0]], cart_position_bins)[0],\n",
    "            np.digitize([state[1]], cart_velocity_bins)[0],\n",
    "            np.digitize([state[2]], pole_angle_bins)[0],\n",
    "            np.digitize([state[3]], angle_rate_bins)[0])\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    env = gym.make('CartPole-v0')\n",
    "    max_num_episodes = 6000\n",
    "    discount = 0.999\n",
    "    eps = 0.001\n",
    "    #eps_decay = 0.0\n",
    "    #eps_min = 0.01\n",
    "    alpha = 0.2\n",
    "\n",
    "    NUM_ITERATIONS = 10\n",
    "    WINNING_MEAN = 170\n",
    "    EPS_ANALYSIS = 0\n",
    "    ALPHA_ANALYSIS = 1\n",
    "    DISCOUNT_ANALYSIS = 2\n",
    "    mode = DISCOUNT_ANALYSIS\n",
    "\n",
    "    # number of discrete states\n",
    "    n_bins = 8\n",
    "    n_bins_angle = 10\n",
    "\n",
    "    # discrete states for each variable\n",
    "    cart_position_bins = pandas.cut([-2.4, 2.4], bins=n_bins, retbins=True)[1][1:-1]\n",
    "    cart_velocity_bins = pandas.cut([-1, 1], bins=n_bins, retbins=True)[1][1:-1]\n",
    "    pole_angle_bins = pandas.cut([-2, 2], bins=n_bins_angle, retbins=True)[1][1:-1]\n",
    "    angle_rate_bins = pandas.cut([-3.5, 3.5], bins=n_bins_angle, retbins=True)[1][1:-1]\n",
    "\n",
    "    array_eps_to_conv = []\n",
    "    if (mode == EPS_ANALYSIS):\n",
    "        eval_array = [0.001,0.003,0.006,0.01,0.013]\n",
    "    elif (mode == ALPHA_ANALYSIS):\n",
    "        eval_array = [0.1,0.2,0.3,0.5,0.7]\n",
    "    else:\n",
    "        eval_array = [0.999,0.8,0.7,0.6,0.5]\n",
    "\n",
    "    for t in range(NUM_ITERATIONS):\n",
    "        array_temp = []\n",
    "        print(t)\n",
    "\n",
    "        for hyperparameter in eval_array:\n",
    "            if (mode == EPS_ANALYSIS):\n",
    "                has_converged, episodes_to_converge = sarsa_control(env, max_num_episodes, discount, hyperparameter, alpha)\n",
    "            elif (mode == ALPHA_ANALYSIS):\n",
    "                has_converged, episodes_to_converge = sarsa_control(env, max_num_episodes, discount, eps, hyperparameter)\n",
    "            else:\n",
    "                has_converged, episodes_to_converge = sarsa_control(env, max_num_episodes, hyperparameter, eps, alpha)\n",
    "\n",
    "            array_temp.append(episodes_to_converge)\n",
    "            print(hyperparameter, \")the system \", \"has converged\" if (has_converged) else \"hasn't converged\", \" after \", episodes_to_converge, \" episodes.\")\n",
    "\n",
    "        array_eps_to_conv.append(array_temp)\n",
    "\n",
    "    array_eps_to_conv = np.array(array_eps_to_conv)\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111)\n",
    "\n",
    "    if (mode == EPS_ANALYSIS):\n",
    "        title = r'$\\gamma = {:.3f}; \\alpha = {:.3f}$'.format(discount, alpha)\n",
    "        label = r'$\\epsilon$'\n",
    "        name = 'eps_sensibility1.png'\n",
    "        ax.set_ylim((0,2000))\n",
    "    elif (mode == ALPHA_ANALYSIS):\n",
    "        title = r'$\\gamma = {:.3f}; \\epsilon = {:.3f}$'.format(discount, eps)\n",
    "        label = r'$\\alpha$'\n",
    "        name = 'lr_sensibility1.png'\n",
    "        ax.set_ylim((0,1000))\n",
    "    else:\n",
    "        title = r'$\\alpha = {:.3f}; \\epsilon = {:.3f}$'.format(alpha, eps)\n",
    "        label = r'$1-\\gamma$'\n",
    "        eval_array = [np.around(1-disc, decimals=4) for disc in eval_array]\n",
    "        name = 'discount_sensibility1.png'\n",
    "        ax.set_ylim((0,1500))\n",
    "\n",
    "    ax.set_title(title)\n",
    "    ax.set_ylabel('episodes to converge')\n",
    "    ax.set_xlabel(label)\n",
    "    ax.boxplot(array_eps_to_conv, labels=eval_array)\n",
    "    plt.savefig(name)\n",
    "    #plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
